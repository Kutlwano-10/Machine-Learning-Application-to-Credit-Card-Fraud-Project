Hello!

I am really excited about machine-learning and decided to take on this project as the first of many to get more comfortable the models used.

This project covers credit card fraud and is meant to look at a dataset of transactions and predict whether it is fraudulent or not.
We focused on using "class" as our target feature because it simplifies the classification of fraudulent and valid transactions. We employed feature importance analysis to identify 
the most relevant features for our models, selecting the most impactful ones for optimization. Our results indicate that the Support Vector Machine (SVM) consistently outperformed the other models, both before and after optimization, while the Local Outlier Factor (LOF) exhibited the weakest performance. Interestingly, we observed that the LOF model is particularly effective at identifying 
normal transactions. This raises an important question: Is this behavior driven by the hyperparameters we used or by the selected features? Further investigation is required to determine the 
underlying cause.
The data of this project can be found at : https://www.kaggle.com/code/mendozav/credit-card-fraud-detection-project/input.


Acknowledgements: I thank Phodiso Maroeshe (https://github.com/phodiso-7?tab=repositories) for his insightful discussions and his contribution in optimising our models.
